{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip freeze > requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lettura del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('appointment_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Primo label encoder\n",
    "\n",
    "In generale il Label Encoder codifica le etichette di destinazione con un valore compreso tra 0 e n_classi-1.\n",
    "\n",
    "\n",
    "Questo è un primo label encoder che vado ad effettuare su tutto il dataset solo per poter andare a studiare la correlazione tra le features e poter andare a fare features selection in seguito, scartando le features considerate da me meno utili.\n",
    "\n",
    "Come appena detto questo label encoder è usato UNICAMENTE per studiare la correlazione tra features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "for i in dataset:\n",
    "    dataset[i] = label_encoder.fit_transform(dataset[i])\n",
    "    \n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heatmap:\n",
    "\n",
    "Per poter andare a decidere quali features andare a prendere in considerazione e quali no, sono andato ad utilizzare una heatmap, in maniera tale da andare a studiare quella che è la correlazione tra le varie features.\n",
    "\n",
    "Le features che ho scelto di andare a scartare sono:\n",
    "\n",
    "1) **ScheduledDay** e l'**AppointmentDay**, in quanto ho deciso di andare a prendere in considerazione quella che è la \"differenza tra le due\"(Days_of_waiting--> spiegata sotto).\n",
    "\n",
    "2) **Gender**, in quanto non ho visto alcuna correlazione significativa con nessuna features, anzi. L'unico accenno di correlazione \"da notare\", l'ho visto con  Alcoholism, ma non sono comunuque riuscito a notare alcuna relazione effettivamente significativa ai fini della mia analisi o comunque non ho trovato alcun punto di collegamento su cui estrarre informazione utile.\n",
    "\n",
    "3) **Neighbourhood**, in quanto ha dei valori di correlazione insignificanti con tutte le restanti features e quindi ho deciso di non prenderla in considerazione per la mia analisi.\n",
    "\n",
    "4) **PatientId** e **AppointmentID**: valgono le stesse considerazioni fatte ad esempio per **Neighbourhood**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#heatmap per la selezione delle features     \n",
    "correlation = dataset.corr()\n",
    "plt.figure(figsize=(18,18))\n",
    "sns.heatmap(correlation, vmax=1, square=True,annot=True,cmap='cubehelix')\n",
    "plt.title('Correlation between different features')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creazione Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Age:\n",
    "\n",
    "Divido i possibili valori di age presenti in quattro macro-classi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#divisione in classi età\n",
    "def age_division(dataset):\n",
    "    \n",
    "    dataset= dataset.copy()\n",
    "\n",
    "    age = np.asanyarray(dataset['Age'])\n",
    " \n",
    "    for i in range(0, age.size):\n",
    "        if 0 <= age[i] <= 20:\n",
    "            age[i] = 0\n",
    "        elif 21 <= age[i] <= 40:\n",
    "            age[i] = 1\n",
    "        elif 41 <= age[i] <= 90:\n",
    "            age[i] = 2\n",
    "        else:\n",
    "            age[i] = 3\n",
    "            \n",
    "    dataset['Age'] = pd.DataFrame(age)\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Days_of_waiting:\n",
    "\n",
    "Ho deciso di andare a valutare i giorni di attesa di differenza che ci sono tra lo ScheduledDay e l'AppointmentDay.\n",
    "\n",
    "Sono andato ad effettuare un arrotondamento considerando i giorni dei mesi 30."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def days_of_waiting(dataset):\n",
    "    \n",
    "    dataset= dataset.copy()\n",
    "\n",
    "    waiting_days= []\n",
    "\n",
    "    for i in range(dataset.shape[0]):\n",
    "\n",
    "        data_Scheduled, ora_Scheduled= dataset['ScheduledDay'].loc[i].split('T')\n",
    "        data_Appointment, ora_Appointment= dataset['AppointmentDay'].loc[i].split('T')\n",
    "\n",
    "        annoS, meseS, giornoS= data_Scheduled.split('-')\n",
    "        annoA, meseA, giornoA= data_Appointment.split('-')\n",
    "\n",
    "        months_difference= (int(meseA)-int(meseS))*30\n",
    "\n",
    "        if(int(annoS)==int(annoA)):\n",
    "            if(int(meseS)==int(meseA)):\n",
    "                if(int(giornoS)==int(giornoA)):\n",
    "                    waiting_days.append(0)\n",
    "                else:\n",
    "                    waiting_days.append(abs(int(giornoA)-int(giornoS)))\n",
    "            else:\n",
    "                waiting_days.append(abs(int(giornoA)+months_difference-int(giornoS)))\n",
    "        else:\n",
    "            years_difference= (int(annoA)-int(annoS))*365\n",
    "            waiting_days.append(abs(int(giornoA)+months_difference+years_difference-int(giornoS)))                        \n",
    "\n",
    "    dataset['days_of_waiting'] = waiting_days\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transf(dataset):\n",
    "    \n",
    "    dataset= dataset.copy()\n",
    "    \n",
    "    dataset= age_division(dataset)\n",
    "    dataset= days_of_waiting(dataset)\n",
    "    \n",
    "    dataset = dataset.drop(columns=['AppointmentDay','AppointmentID','Gender','Neighbourhood','PatientId','ScheduledDay'])\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csv = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_csv = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = transf(train_csv.copy())\n",
    "test = transf(test_csv.copy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Secondo label encoder\n",
    "\n",
    "Come si può notare questo è il secondo Label encoder utilizzato. Perchè? Il perchè sta nel fatto che come detto in precedenza il primo Label Encoder è usato solo ed unicamente per andare ad effettuare un'analisi della correlazione di TUTTE le features. Una volta decise le features da scartare, mi sono reso conto che quasi tutte quelle da me scartate erano di tipo 'object'. L'unica variabile di tale tipo a me rimasta è ovviamente la variabile sulla quale andare a fare predizione. Sono quindi andato ad effettuare il Label Encoding per convertire i valori di 'No' e 'Yes' di **No-show** in 0 e 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "\n",
    "train['No-show'] = label_encoder.fit_transform(train['No-show'])\n",
    "test['No-show'] = label_encoder.fit_transform(test['No-show'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train, Y_test = train['No-show'], test['No-show']\n",
    "X_train, X_test = train.drop(columns=['No-show']), test.drop(columns=['No-show'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr = DecisionTreeClassifier(criterion='entropy', random_state=0, max_depth=5)\n",
    "\n",
    "\n",
    "#fit e prediction\n",
    "tr.fit(X_train, Y_train)\n",
    "pred = tr.predict(X_test)\n",
    "print('Accuracy:',accuracy_score(Y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
